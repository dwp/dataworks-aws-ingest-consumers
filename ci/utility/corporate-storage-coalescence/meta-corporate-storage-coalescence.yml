meta-corporate-storage-coalescence:
  plan:
    run-coalesce-task:
      task: run-coalesce-task
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: 0.0.25
        params:
          AWS_REGION: ((dataworks.aws_region))
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          ASSUME_DURATION: 43200
        run:
          dir: dataworks-corporate-storage-coalescence
          path: sh
          args:
            - -exc
            - |
              source /assume-role
              set +x

              export EXIT_CODE_FOR_CREDENTIALS_ERROR=2

              echo "Switching to script directory"
              cd coalescer

              echo "Installing python required packages"
              pip install -r requirements.txt --use-feature=2020-resolver

              if [[ -z "${THREAD_COUNT}" ]]; then
                echo "Defaulting thread count to 1"
                export THREAD_COUNT=1
              fi

              function run_script {
                local prefix="${1}"
                python main.py -b "${S3_BUCKET_ID}" -f "${MAX_SIZE_FILES}" -s "${MAX_SIZE_BYTES}" -p "${prefix}" -t "${THREAD_COUNT}"
                local result=$?

                echo "Checking result of coalesce"
                if [ $result -eq $EXIT_CODE_FOR_CREDENTIALS_ERROR ] && [ "${AUTO_RERUN_ON_CRENDENTIALS_TIMEOUT}" -eq "true" ]; then
                    echo "Assuming credentials again and re-running script due to exit code of '$result' and auto-run setting of '${AUTO_RERUN_ON_CRENDENTIALS_TIMEOUT}'"
                    source /assume-role
                    run_script "${prefix}"
                elif [ ! $result -eq 0 ]; then
                    echo "Exiting with error due to failed coalesce with exit code of '$result' and auto-run setting of '${AUTO_RERUN_ON_CRENDENTIALS_TIMEOUT}'"
                    exit 1
                else
                    echo "Coalesce successful"
                    exit 0
                fi
              }

              function execute_coalesce {
                local date_to_run=$(date -d "$1" +'%Y/%m/%d')
                local full_prefix="${S3_BASE_PREFIX}/${date_to_run}/"

                echo "Running coalesce for bucket of '${S3_BUCKET_ID}', file max of '${MAX_SIZE_FILES}', size max of '${MAX_SIZE_BYTES}', prefix of '${full_prefix}' and thread count of '${THREAD_COUNT}'"

                if [[ -z "${RUN_IN_PARTITION_BATCHES_OF_THIS_SIZE}" ]]; then
                  run_script "${full_prefix}" &
                  wait $!
                  exit $?
                else
                  for ((i=0; i<=20; i+=RUN_IN_PARTITION_BATCHES_OF_THIS_SIZE)); do
                      pids=""
                      FAILURE_COUNT=0

                      echo "Executing coalesce batch starting with count of '$partition_count'"

                      for partition_count in "${s[@]:i:i+RUN_IN_PARTITION_BATCHES_OF_THIS_SIZE}"; do
                        full_prefix_with_partition= "${full_prefix}_${partition_count}_"
                        run_script "${full_prefix_with_partition}" &
                        pids="$pids $!"
                      done
                      
                      echo "Waiting for all executions in batch to finish"

                      for pid in $pids; do
                        wait $pid
                        if [ ! $result -eq 0 ]; then
                          ((FAILURE_COUNT=FAILURE_COUNT+1))
                        fi
                      done
                      
                      echo "Checking results of batch"

                      if [[ $FAILURE_COUNT -gt 0 ]]; then
                        echo "Exiting abnormally due to '$FAILURE_COUNT' failed executions in batch starting with count of '$partition_count'"
                        exit 1
                      fi
                      
                      echo "Batch succeeded"
                  done
              }

              function set_storage_type_values {
                echo "Setting corporate storage values for given storage type"

                if [[ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]]; then
                  echo "Setting equalities corporate storage values"
                  export S3_BASE_PREFIX=$(cat ../../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
                  export MAX_SIZE_FILES=$(cat ../../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                  export MAX_SIZE_BYTES=$(cat ../../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
                elif [[ "${CORPORATE_STORAGE_TYPE}" == "audit" ]]; then
                  echo "Setting audit corporate storage values"
                  export S3_BASE_PREFIX=$(cat ../../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
                  export MAX_SIZE_FILES=$(cat ../../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                  export MAX_SIZE_BYTES=$(cat ../../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
                elif [[ "${CORPORATE_STORAGE_TYPE}" == "main" ]]; then
                  echo "Setting main corporate storage values"
                  export S3_BASE_PREFIX=$(cat ../../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
                  export MAX_SIZE_FILES=$(cat ../../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                  export MAX_SIZE_BYTES=$(cat ../../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
                else
                  echo "Unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                  exit 1
                fi

                echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}', MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
              }

              function set_global_storage_values {
                echo "Setting corporate storage values which apply to all storage types"
                if [[ -z "${START_DATE}" ]]; then
                  export FIRST_DATE_TO_RUN=$(date -d "yesterday" +"%Y%m%d")
                else
                  export FIRST_DATE_TO_RUN=$(date -d "${START_DATE}" +"%Y%m%d")
                fi

                if [[ -z "${END_DATE}" ]]; then
                  export LAST_DATE_TO_RUN="${FIRST_DATE_TO_RUN}"
                else
                  export LAST_DATE_TO_RUN=$(date -d "${END_DATE}" +"%Y%m%d")
                fi

                export S3_BUCKET_ID=$(cat ../../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
                echo "Set FIRST_DATE_TO_RUN to '${FIRST_DATE_TO_RUN}', LAST_DATE_TO_RUN to '${LAST_DATE_TO_RUN}' and S3_BUCKET_ID to '${S3_BUCKET_ID}'"

                if [[ ${FIRST_DATE_TO_RUN} -gt ${LAST_DATE_TO_RUN} ]]; then
                  echo "Exiting abnormally because start date to after end date"
                  exit 1
                fi
              }

              set_global_storage_values
              set_storage_type_values

              current_date_to_run="${FIRST_DATE_TO_RUN}"
              while [ ${current_date_to_run} -le ${LAST_DATE_TO_RUN} ]; do
                execute_coalesce "${current_date_to_run}"
                current_date_to_run=$(date -d "${current_date_to_run}+1 day" +"%Y%m%d")
              done
        inputs:
          - name: dataworks-corporate-storage-coalescence
          - name: meta
          - name: terraform-output-ingest
          - name: terraform-output-ingest-consumers