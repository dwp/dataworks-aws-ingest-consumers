meta-corporate-storage-coalescence:
  plan:
    run-coalesce-task:
      task: run-coalesce-task
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: 0.0.25
        params:
          AWS_REGION: ((dataworks.aws_region))
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          ASSUME_DURATION: 43200
        run:
          dir: dataworks-corporate-storage-coalescence
          path: sh
          args:
            - -exc
            - |
              source /assume-role
              set +x

              export EXIT_CODE_FOR_CREDENTIALS_ERROR=2

              echo "Switching to script directory"
              cd coalescer

              echo "Installing python required packages"
              pip install -r requirements.txt --use-feature=2020-resolver

              if [[ -z "${THREAD_COUNT}" ]]; then
                echo "Defaulting thread count to 1"
                export THREAD_COUNT=1
              fi

              function run_script {
                local prefix="${1}"
                local partition="${2}"

                if [[ ! -z "${partition}" ]]; then
                  python main.py -b "${S3_BUCKET_ID}" -f "${MAX_SIZE_FILES}" -s "${MAX_SIZE_BYTES}" -p "${prefix}" -t "${THREAD_COUNT}" -n "${partition}"
                else
                  python main.py -b "${S3_BUCKET_ID}" -f "${MAX_SIZE_FILES}" -s "${MAX_SIZE_BYTES}" -p "${prefix}" -t "${THREAD_COUNT}"
                fi

                local result=$?

                echo "Checking result of coalesce"
                if [[ $result -eq $EXIT_CODE_FOR_CREDENTIALS_ERROR ]] && [[ "${AUTO_RERUN_ON_CRENDENTIALS_TIMEOUT}" -eq "true" ]]; then
                    echo "Assuming credentials again and re-running script due to exit code of '$result' and auto-run setting of '${AUTO_RERUN_ON_CRENDENTIALS_TIMEOUT}'"
                    source /assume-role
                    run_script "${prefix}" "${partition}"
                elif [[ ! $result -eq 0 ]]; then
                    echo "Exiting with error due to failed coalesce with exit code of '$result' and auto-run setting of '${AUTO_RERUN_ON_CRENDENTIALS_TIMEOUT}'"
                    exit 1
                else
                    echo "Coalesce successful"
                    exit 0
                fi
              }

              function execute_coalesce {
                local date_to_run=$(date -d "$1" +'%Y/%m/%d')
                local full_prefix="${S3_BASE_PREFIX}/${date_to_run}/"

                echo "Running coalesce for bucket of '${S3_BUCKET_ID}', file max of '${MAX_SIZE_FILES}', size max of '${MAX_SIZE_BYTES}', prefix of '${full_prefix}' and thread count of '${THREAD_COUNT}'"

                if [[ -z "${RUN_IN_PARTITION_BATCHES_OF_THIS_SIZE}" ]]; then
                  run_script "${full_prefix}" &
                  wait $!
                  exit $?
                else
                  batch_start_count=0

                  while [[ $batch_start_count -le 18 ]]; do
                      local pids=""
                      local failure_count=0
                      local partition_count=$batch_start_count
                      local batch_end_count=$((batch_start_count + $RUN_IN_PARTITION_BATCHES_OF_THIS_SIZE))

                      echo "Running batch with start of '$partition_count'"

                      while [[ $partition_count -lt $batch_end_count ]]; do
                        if [[ $partition_count -le 18 ]]; then
                          echo "Running partition count of '$partition_count'"
                          run_script "${full_prefix}" "${partition_count}" &
                          pids="$pids $!"
                        fi
                        partition_count=$(( partition_count + 1 ))
                      done

                      echo "Waiting for all executions in batch to finish"

                      for pid in $pids; do
                        wait $pid
                        local result=$?
                        if [[ ! $result -eq 0 ]]; then
                          failure_count=$((failure_count + 1))
                        fi
                      done

                      echo "Checking results of batch"

                      if [[ $failure_count -gt 0 ]]; then
                        echo "Exiting abnormally due to '${failure_count}' failed executions in batch starting with count of '$partition_count'"
                        exit 1
                      fi

                      echo "Batch succeeded"
                      batch_start_count=$(( batch_start_count + $RUN_IN_PARTITION_BATCHES_OF_THIS_SIZE ))
                  done
                fi
              }

              function set_storage_type_values {
                echo "Setting corporate storage values for given storage type"

                if [[ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]]; then
                  echo "Setting equalities corporate storage values"
                  export S3_BASE_PREFIX=$(cat ../../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
                  export MAX_SIZE_FILES=$(cat ../../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                  export MAX_SIZE_BYTES=$(cat ../../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
                elif [[ "${CORPORATE_STORAGE_TYPE}" == "audit" ]]; then
                  echo "Setting audit corporate storage values"
                  export S3_BASE_PREFIX=$(cat ../../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
                  export MAX_SIZE_FILES=$(cat ../../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                  export MAX_SIZE_BYTES=$(cat ../../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
                elif [[ "${CORPORATE_STORAGE_TYPE}" == "main" ]]; then
                  echo "Setting main corporate storage values"
                  export S3_BASE_PREFIX=$(cat ../../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
                  export MAX_SIZE_FILES=$(cat ../../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                  export MAX_SIZE_BYTES=$(cat ../../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
                else
                  echo "Unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                  exit 1
                fi

                echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}', MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
              }

              function set_global_storage_values {
                echo "Setting corporate storage values which apply to all storage types"
                if [[ -z "${START_DATE}" ]]; then
                  export FIRST_DATE_TO_RUN=$(date -d "yesterday" +"%Y%m%d")
                else
                  export FIRST_DATE_TO_RUN=$(date -d "${START_DATE}" +"%Y%m%d")
                fi

                if [[ -z "${END_DATE}" ]]; then
                  export LAST_DATE_TO_RUN="${FIRST_DATE_TO_RUN}"
                else
                  export LAST_DATE_TO_RUN=$(date -d "${END_DATE}" +"%Y%m%d")
                fi

                export S3_BUCKET_ID=$(cat ../../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
                echo "Set FIRST_DATE_TO_RUN to '${FIRST_DATE_TO_RUN}', LAST_DATE_TO_RUN to '${LAST_DATE_TO_RUN}' and S3_BUCKET_ID to '${S3_BUCKET_ID}'"

                if [[ ${FIRST_DATE_TO_RUN} -gt ${LAST_DATE_TO_RUN} ]]; then
                  echo "Exiting abnormally because start date to after end date"
                  exit 1
                fi
              }

              set_global_storage_values
              set_storage_type_values

              current_date_to_run="${FIRST_DATE_TO_RUN}"
              while [[ ${current_date_to_run} -le ${LAST_DATE_TO_RUN} ]]; do
                execute_coalesce "${current_date_to_run}"
                current_date_to_run=$(date -d "${current_date_to_run}+1 day" +"%Y%m%d")
              done
        inputs:
          - name: dataworks-corporate-storage-coalescence
          - name: meta
          - name: terraform-output-ingest
          - name: terraform-output-ingest-consumers