meta-batch-coalescer:
  plan:
    terraform-common-config:
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: ((dataworks.terraform_repository))
            version: ((dataworks.terraform_version))
            tag: ((dataworks.terraform_version))
        params:
          TF_INPUT: false
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
    terraform-output-ingest:
      task: terraform-output-ingest
      .: (( inject meta-batch-coalescer.plan.terraform-common-config ))
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: ((dataworks.terraform_repository))
            version: ((dataworks.terraform_version))
            tag: ((dataworks.terraform_version))
        run:
          path: sh
          args:
            - -exc
            - |
              terraform workspace show
              terraform init
              terraform output --json > ../terraform-output-ingest/outputs.json
          dir: aws-ingestion
        inputs:
          - name: aws-ingestion
        outputs:
          - name: terraform-output-ingest
    terraform-output-internal-compute:
      task: terraform-output-internal-compute
      .: (( inject meta-batch-coalescer.plan.terraform-common-config ))
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: ((dataworks.terraform_repository))
            version: ((dataworks.terraform_version))
            tag: ((dataworks.terraform_version))
        run:
          path: sh
          args:
            - -exc
            - |
              terraform workspace show
              terraform init
              terraform output --json > ../terraform-output-internal-compute/outputs.json
          dir: aws-internal-compute
        inputs:
          - name: aws-internal-compute
        outputs:
          - name: terraform-output-internal-compute   
    storage-batch-coalescer:
      task: storage-batch-coalescer
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: ((dataworks.docker_awscli_repository))
            version: ((dataworks.docker_awscli_version))
        inputs:
          - name: meta
          - name: terraform-output-ingest
        params:
          AWS_REGION: ((dataworks.aws_region))
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          TIMEOUT: 900   # Time (in minutes) to wait for job to complete
          ASSUME_DURATION: 14400
        run:
          path: sh
          args:
            - -exc
            - |
              source /assume-role
              pipeline_name=`cat "meta/build_pipeline_name"`
              job_name=`cat "meta/build_job_name"`
              build_number=`cat "meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              export S3_BUCKET_ID="$(cat terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')"
              export S3_PREFIX="$(cat terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')"
              job_id=$(aws batch submit-job --job-queue batch_corporate_storage_coalescer --job-definition batch_corporate_storage_coalescer_job_storage --job-name ${pipeline_name}_${job_name}_${build_number_safe} --parameters s3-bucket-id="\"${S3_BUCKET_ID}\"",s3-prefix="\"${S3_PREFIX}\"",partition="\"${PARTITION}\"",threads="\"${THREADS}\"",max-files="\"${MAXFILES}\"",max-size="\"${MAXSIZE}\"",date-to-add="\"${DATETOADD}\""| jq -e --raw-output .jobId)
              set +x
              if [[ -z $job_id ]]; then
                echo "Error submitting job, empty job_id received"
                exit 1
              fi
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${job_id} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unkwnown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done
              exit 1
    manifests-batch-coalescer:
      task: manifests-batch-coalescer
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: ((dataworks.docker_awscli_repository))
            version: ((dataworks.docker_awscli_version))
        inputs:
          - name: meta
          - name: terraform-output-ingest
          - name: terraform-output-internal-compute
        params:
          AWS_REGION: ((dataworks.aws_region))
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          TIMEOUT: 900   # Time (in minutes) to wait for job to complete
          ASSUME_DURATION: 14400
        run:
          path: sh
          args:
            - -exc
            - |
              source /assume-role
              pipeline_name=`cat "meta/build_pipeline_name"`
              job_name=`cat "meta/build_job_name"`
              build_number=`cat "meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              export S3_BUCKET_ID="$(cat terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')"
              export S3_PREFIX="$(cat terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')"
              job_id=$(aws batch submit-job --job-queue batch_corporate_storage_coalescer --job-definition batch_corporate_storage_coalescer_job_manifests --job-name ${pipeline_name}_${job_name}_${build_number_safe} --parameters s3-bucket-id="\"${S3_BUCKET_ID}\"",s3-prefix="\"${S3_PREFIX}\"",partition="\"${PARTITION}\"",threads="\"${THREADS}\"",max-files="\"${MAXFILES}\"",max-size="\"${MAXSIZE}\"",date-to-add="\"${DATETOADD}\""| jq -e --raw-output .jobId)
              set +x
              if [[ -z $job_id ]]; then
                echo "Error submitting job, empty job_id received"
                exit 1
              fi
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${job_id} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unkwnown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done
              exit 1
    manifests-audit-batch-coalescer:
      task: manifests-audit-batch-coalescer
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: ((dataworks.docker_awscli_repository))
            version: ((dataworks.docker_awscli_version))
        inputs:
          - name: meta
          - name: terraform-output-ingest
          - name: terraform-output-internal-compute
        params:
          AWS_REGION: ((dataworks.aws_region))
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          TIMEOUT: 900   # Time (in minutes) to wait for job to complete
          ASSUME_DURATION: 14400
        run:
          path: sh
          args:
            - -exc
            - |
              source /assume-role
              pipeline_name=`cat "meta/build_pipeline_name"`
              job_name=`cat "meta/build_job_name"`
              build_number=`cat "meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              export S3_BUCKET_ID="$(cat terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')"
              export S3_PREFIX="$(cat terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')"
              job_id=$(aws batch submit-job --job-queue batch_corporate_storage_coalescer --job-definition batch_corporate_storage_coalescer_job_manifests_audit --job-name ${pipeline_name}_${job_name}_${build_number_safe} --parameters s3-bucket-id="\"${S3_BUCKET_ID}\"",s3-prefix="\"${S3_PREFIX}\"",partition="\"${PARTITION}\"",threads="\"${THREADS}\"",max-files="\"${MAXFILES}\"",max-size="\"${MAXSIZE}\"",date-to-add="\"${DATETOADD}\""| jq -e --raw-output .jobId)
              set +x
              if [[ -z $job_id ]]; then
                echo "Error submitting job, empty job_id received"
                exit 1
              fi
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${job_id} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unkwnown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done
              exit 1
