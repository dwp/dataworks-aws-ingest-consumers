groups:
- jobs:
  - audit-development
  - audit-qa
  name: audit
- jobs:
  - update-pipeline-corporate-storage-coalescence
  name: update-pipeline
jobs:
- max_in_flight: 1
  name: audit-development
  plan:
  - in_parallel:
    - put: meta
      resource: meta-development
    - get: dataworks-corporate-storage-coalescence
      trigger: false
    - get: aws-ingestion
      trigger: false
    - get: dataworks-aws-ingest-consumers
      trigger: false
  - config:
      image_resource:
        source:
          repository: dwpdigital/jinja-yaml-aws
          tag: 0.0.19
          version: 0.0.19
        type: docker-image
      inputs:
      - name: dataworks-aws-ingest-consumers
      outputs:
      - name: terraform-bootstrap
      platform: linux
      run:
        args:
        - -exc
        - |
          python bootstrap_terraform.py
          cp terraform.tf ../terraform-bootstrap
        dir: dataworks-aws-ingest-consumers
        path: sh
    params:
      AWS_REGION: eu-west-2
    task: terraform-bootstrap
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: aws-ingestion
        outputs:
        - name: terraform-output-ingest
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-ingest/outputs.json
          dir: aws-ingestion
          path: sh
      task: terraform-output-ingest
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: dataworks-aws-ingest-consumers
        - name: terraform-bootstrap
        outputs:
        - name: terraform-output-ingest-consumers
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            cp ../terraform-bootstrap/terraform.tf .
            ls -la terraform.tf
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-ingest-consumers/outputs.json
          dir: dataworks-aws-ingest-consumers
          path: sh
      task: terraform-output-ingest-consumers
  - config:
      image_resource:
        source:
          repository: ((dataworks.docker_python_boto_behave_repository))
          tag: 0.0.25
        type: docker-image
      inputs:
      - name: dataworks-corporate-storage-coalescence
      - name: meta
      - name: terraform-output-ingest
      - name: terraform-output-ingest-consumers
      params:
        ASSUME_DURATION: 43200
        AWS_DEFAULT_REGION: ((dataworks.aws_region))
        AWS_REGION: ((dataworks.aws_region))
        CORPORATE_STORAGE_TYPE: audit
        DATE_TO_RUN_ON: yesterday
      platform: linux
      run:
        args:
        - -exc
        - |
          source /assume-role
          set +x

          echo "Setting corporate storage values which apply to all storage types"
          date_to_run=$(date -d "${DATE_TO_RUN_ON}" +"%y/%M/%d")
          s3_bucket_id=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
          echo "Set date_to_run to '${date_to_run}' and s3_bucket_id to '${s3_bucket_id}'"

          echo "Setting corporate storage values for given storage type"

          if [[ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]]; then
            echo "Setting equalities corporate storage values"
            s3_base_prefix=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
            max_size_files=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
            max_size_bytes=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
          elif [[ "${CORPORATE_STORAGE_TYPE}" == "audit" ]]; then
            echo "Setting audit corporate storage values"
            s3_base_prefix=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
            max_size_files=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
            max_size_bytes=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
          else
            echo "Setting main corporate storage values"
            s3_base_prefix=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
            max_size_files=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
            max_size_bytes=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
          else
            echo "Unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
            exit 1
          fi

          echo "Set s3_base_prefix to '${s3_base_prefix}', max_size_files to '${max_size_files}' and max_size_bytes to '${max_size_bytes}'"

          full_s3_prefix="${s3_base_prefix}/${date_to_run}/"
          echo "Set full_s3_prefix to '${full_s3_prefix}'"

          python main.py -b "${s3_bucket_id}" -f "${max_size_files}" -s "${max_size_bytes}" -p "${full_s3_prefix}"
        dir: dataworks-corporate-storage-coalescence
        path: sh
    task: coalesce-audit-storage-for-yesterday
- max_in_flight: 1
  name: audit-qa
  plan:
  - in_parallel:
    - put: meta
      resource: meta-qa
    - get: dataworks-corporate-storage-coalescence
      trigger: false
    - get: aws-ingestion
      trigger: false
    - get: dataworks-aws-ingest-consumers
      trigger: false
  - config:
      image_resource:
        source:
          repository: dwpdigital/jinja-yaml-aws
          tag: 0.0.19
          version: 0.0.19
        type: docker-image
      inputs:
      - name: dataworks-aws-ingest-consumers
      outputs:
      - name: terraform-bootstrap
      platform: linux
      run:
        args:
        - -exc
        - |
          python bootstrap_terraform.py
          cp terraform.tf ../terraform-bootstrap
        dir: dataworks-aws-ingest-consumers
        path: sh
    params:
      AWS_REGION: eu-west-2
    task: terraform-bootstrap
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: aws-ingestion
        outputs:
        - name: terraform-output-ingest
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: qa
        platform: linux
        run:
          args:
          - -exc
          - |
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-ingest/outputs.json
          dir: aws-ingestion
          path: sh
      task: terraform-output-ingest
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: dataworks-aws-ingest-consumers
        - name: terraform-bootstrap
        outputs:
        - name: terraform-output-ingest-consumers
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: qa
        platform: linux
        run:
          args:
          - -exc
          - |
            cp ../terraform-bootstrap/terraform.tf .
            ls -la terraform.tf
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-ingest-consumers/outputs.json
          dir: dataworks-aws-ingest-consumers
          path: sh
      task: terraform-output-ingest-consumers
  - config:
      image_resource:
        source:
          repository: ((dataworks.docker_python_boto_behave_repository))
          tag: 0.0.25
        type: docker-image
      inputs:
      - name: dataworks-corporate-storage-coalescence
      - name: meta
      - name: terraform-output-ingest
      - name: terraform-output-ingest-consumers
      params:
        ASSUME_DURATION: 43200
        AWS_DEFAULT_REGION: ((dataworks.aws_region))
        AWS_REGION: ((dataworks.aws_region))
        CORPORATE_STORAGE_TYPE: audit
        DATE_TO_RUN_ON: yesterday
      platform: linux
      run:
        args:
        - -exc
        - |
          source /assume-role
          set +x

          echo "Setting corporate storage values which apply to all storage types"
          date_to_run=$(date -d "${DATE_TO_RUN_ON}" +"%y/%M/%d")
          s3_bucket_id=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
          echo "Set date_to_run to '${date_to_run}' and s3_bucket_id to '${s3_bucket_id}'"

          echo "Setting corporate storage values for given storage type"

          if [[ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]]; then
            echo "Setting equalities corporate storage values"
            s3_base_prefix=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
            max_size_files=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
            max_size_bytes=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
          elif [[ "${CORPORATE_STORAGE_TYPE}" == "audit" ]]; then
            echo "Setting audit corporate storage values"
            s3_base_prefix=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
            max_size_files=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
            max_size_bytes=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
          else
            echo "Setting main corporate storage values"
            s3_base_prefix=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
            max_size_files=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
            max_size_bytes=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
          else
            echo "Unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
            exit 1
          fi

          echo "Set s3_base_prefix to '${s3_base_prefix}', max_size_files to '${max_size_files}' and max_size_bytes to '${max_size_bytes}'"

          full_s3_prefix="${s3_base_prefix}/${date_to_run}/"
          echo "Set full_s3_prefix to '${full_s3_prefix}'"

          python main.py -b "${s3_bucket_id}" -f "${max_size_files}" -s "${max_size_bytes}" -p "${full_s3_prefix}"
        dir: dataworks-corporate-storage-coalescence
        path: sh
    task: coalesce-audit-storage-for-yesterday
- name: update-pipeline-corporate-storage-coalescence
  plan:
  - get: dataworks-aws-ingest-consumers
    resource: dataworks-aws-ingest-consumers-update-pipeline
    trigger: true
  - config:
      image_resource:
        source:
          repository: ((dataworks.docker_aviator_repository))
          version: ((dataworks.docker_aviator_version))
        type: docker-image
      inputs:
      - name: dataworks-aws-ingest-consumers
      outputs:
      - name: pipeline
      platform: linux
      run:
        args:
        - -exc
        - |
          sed -i 's/fly/nofly/' aviator-corporate-storage-coalescence.yml
          /usr/bin/aviator -f aviator-corporate-storage-coalescence.yml
          mv aviator_corporate_storage_coalescence_pipeline.yml ../pipeline
          mv ci/vars.yml ../pipeline
        dir: dataworks-aws-ingest-consumers
        path: sh
    task: aviator
  - file: pipeline/aviator_corporate_storage_coalescence_pipeline.yml
    set_pipeline: corporate-storage-coalescence
    var_files:
    - pipeline/vars.yml
meta-corporate-storage-coalescence:
  plan:
    run-coalesce-task:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: 0.0.25
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            echo "Setting corporate storage values which apply to all storage types"
            date_to_run=$(date -d "${DATE_TO_RUN_ON}" +"%y/%M/%d")
            s3_bucket_id=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
            echo "Set date_to_run to '${date_to_run}' and s3_bucket_id to '${s3_bucket_id}'"

            echo "Setting corporate storage values for given storage type"

            if [[ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]]; then
              echo "Setting equalities corporate storage values"
              s3_base_prefix=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              max_size_files=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
              max_size_bytes=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
            elif [[ "${CORPORATE_STORAGE_TYPE}" == "audit" ]]; then
              echo "Setting audit corporate storage values"
              s3_base_prefix=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              max_size_files=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
              max_size_bytes=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
            else
              echo "Setting main corporate storage values"
              s3_base_prefix=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              max_size_files=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
              max_size_bytes=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
            else
              echo "Unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
              exit 1
            fi

            echo "Set s3_base_prefix to '${s3_base_prefix}', max_size_files to '${max_size_files}' and max_size_bytes to '${max_size_bytes}'"

            full_s3_prefix="${s3_base_prefix}/${date_to_run}/"
            echo "Set full_s3_prefix to '${full_s3_prefix}'"

            python main.py -b "${s3_bucket_id}" -f "${max_size_files}" -s "${max_size_bytes}" -p "${full_s3_prefix}"
          dir: dataworks-corporate-storage-coalescence
          path: sh
      task: run-coalesce-task
resource_types:
- name: pull-request
  source:
    repository: teliaoss/github-pr-resource
    tag: latest
  type: docker-image
- name: ami
  source:
    repository: chrisscottthomas/ami-resource
    tag: latest
  type: docker-image
- name: meta
  source:
    repository: olhtbr/metadata-resource
    tag: 2.0.1
  type: docker-image
resources:
- check_every: 5m
  name: dataworks-aws-ingest-consumers-update-pipeline
  source:
    access_token: ((dataworks-secrets.concourse_github_pat))
    branch: master
    paths:
    - ci/utility/corporate-storage-coalescence/*
    - ci/shared/*
    - ci/vars.yml
    - aviator-corporate-storage-coalescence.yml
    uri: https://github.com/dwp/dataworks-aws-ingest-consumers.git
  type: git
  webhook_token: ((dataworks.concourse_github_webhook_token))
- check_every: 5m
  name: dataworks-corporate-storage-coalescence
  source:
    access_token: ((dataworks-secrets.concourse_github_pat))
    branch: master
    uri: https://github.com/dwp/dataworks-corporate-storage-coalescence.git
  type: git
  webhook_token: ((dataworks.concourse_github_webhook_token))
- check_every: 5m
  name: dataworks-aws-ingest-consumers
  source:
    access_token: ((dataworks-secrets.concourse_github_pat))
    branch: master
    uri: https://github.com/dwp/dataworks-aws-ingest-consumers.git
  type: git
  webhook_token: ((dataworks.concourse_github_webhook_token))
- check_every: 5m
  name: aws-ingestion
  source:
    api_endpoint: https://((dataworks.enterprise_github_url))/api/v3/
    branch: master
    password: ((dataworks-secrets.enterprise_github_pat))
    uri: https://((dataworks.enterprise_github_url))/dip/aws-ingestion.git
    username: ((dataworks.enterprise_github_username))
  type: git
  webhook_token: ((dataworks.concourse_github_webhook_token))
- name: meta-development
  type: meta
- name: meta-qa
  type: meta
